本片文章来自`redis`[官方文档](https://redis.io/topics/lru-cache)

`LRU(Least Recently Used)`是`redis`驱逐方式中的其中一种，`redis`中的`LRU`其实是近似的实现而不是严格的实现了`LRU`算法。

可以通过`redis.conf`或者在运行时使用[CONFIG SET](https://redis.io/commands/config-set) 命令指定`redis`最大的使用内存。当内存到达指定的大小(`maxmemory`)时就会触发不同的`policies`（政策）：可能是返回报错信息，也可能是驱逐一些旧的数据。

### 驱逐政策

当`redis`的数据量到达配置的最大内存使用量时会触发的政策有以下几种：

* **noeviction**：不驱逐数据直接返回报错信息
* **allkeys-lru**：根据`LRU`算法驱逐数据
* **volatile-lru**：和**allkeys-lru**一样，不过只对有`expire set`的数据起作用
* **allkeys-random**：随机驱逐数据
* **volatile-random**：和**allkeys-random**，不过只对有`expire set`的数据起作用
* **volatile-ttl**：驱逐有`expire set`的数据，同时优先驱逐`TTL`较短的数据

当你设置了`volatile-lru, volatile-random, volatile-ttl`其中一种方式时，如果没有找到满足条件的数据时它们的表现将和`noeviction`一样

**经验之谈**

* 如果数据呈现幂律分布（类似二八定律），既一部分的数据被访问频率远大于其他数据，而且你不确定选哪种政策时就选`allkeys-lru`
* 如果是周期循环访问（扫表）或者期望数据均匀分布是就用`allkeys-random`
* 如果想让`redis`通过数据所设置的`TTL`进行驱逐时可以使用`volatile-ttl`

`volatile-lru`和`volatile-random`政策通常用在既有缓存数据又有持久化数据的单个实例中，当然运行两个`redis`实例来避免这种混用的情况是更好的选择（谁说不是呢，但是资金有时不允许啊）

不要因为内存吃紧而使用对不需要`TTL`的数据设置`expire`。第一是设置`expire`需要额外的内存，第二想`allkeys-lru`这样的政策对内存管理更高效（以前我经常这样用，看来是个坏习惯）

### 驱逐过程

* 客户端运行了新命令，需要添加更多数据
* `redis`通过内存检查，发现超出了最大内存限制，它会根据政策驱逐数据
* 执行新的命令，如此反复

### 近似LRU算法

上面提到`redis`的`LRU`是近似实现也就是说被驱逐的值可能不是真正的最久没被使用的数据。`redis`的实现是对一小部分的数据进行采样，最后在样本中使用`LRU`算法进行数据驱逐

`redis 3.0`以后引入一个回收候选数据池来改进算法

我们可以通过调整采样数量(`maxmemory-samples`)来对算法的精确性进行调整

`redis`之所以不严格实现`LRU`算法是因为需要更多的内存来实现它。从下面图片中我们可以看到近似的`LRU`也有不错的效果

![lru_comparison](/assets/images/lru_comparison.png)

上图显示了用一定量的数据写满`redis`，然后从头到尾访问一边数据，这么做的为的是在`LRU`算法中第一个数据将会被第一个驱逐。接下来我们插入超过数据量50%的数据，确保一半以上的就数据会被驱逐。

上图有三种颜色的点，形成了三条清晰的数据带

* 浅灰色带表示被驱逐的数据
* 灰色带表示没有被驱逐的数据
* 绿色带表示新增的数据

理论上我们实现LRU时，在原来那部分key中，前半部分将会被删除。Redis中实现的LRU只能有概率的删除原有的key。

同样是5个样本我们可以看到Redis3.0比Redis2.8更接近于真实的LRU算法，在2.8中更多的长时间未访问的数据还继续保留。同时我们能看到在Redis3.0中使用样本数为10的话，近似算法很接近理论表现。

LRU只是一个预测key是否可能在将来被访问的模型。如果我们的数据访问模式高度符合幂律规则，LRU近似算法能很好处理大多数的建的访问。

在模拟中我们发现在幂律的访问模式下，理论上的LRU和Redis的近似实现差别很小或者是没有差距。

当然我们可以将样本大小增加到10（会增加额外的CPU使用）使得近似算法与真实的LRU更接近，同时检查这样是否会影响我们的缓存命中率。

在生产中调试不同的样本大小值非常简单，只要使用`CONFIG SET maxmemory-samples <count>`命令就能进行调整。

### 全新的`LFU`模式

从Redis4.0开始，可以使用全新的[最近最频繁被使用驱逐模式](http://antirez.com/news/109)。在特定情况下这种模式能更好的工作（提供更好的命中/未命中比例），因为使用LFU时Redis需要记录数据的访问频率，所以很好用到的数据会被驱逐而那些经常用到的数据被保留的可能性更高。在LRU中，一条刚被访问的数据却是以前几乎没有被访问过的，这样的数据也不会被删除，也就是那些有更高可能性在将来被访问的数据有被驱逐的风险。LFU不会有这种问题，通常应该更具场景选取不同的访问模式。

以下的政策可以用来配置LFU模式：

* `volatile-lfu`对于有`expire set`的数据使用近似LFU的驱逐
* `allkeys-lfu`对所有数据使用近似LFU的驱逐

和LRU一样Redis采用近似LFU：使用一个被称为[Morris counter](https://en.wikipedia.org/wiki/Approximate_counting_algorithm)的概率计数器来预估对象的访问频率，该计数器只需要几个比特，同时结合一个衰变周期确保计数会随着时间减少：在某些时候，即使数据在过去频繁被访问，我们也不再希望将其视为频繁访问的数据，以便算法可以适应访问模式的转变。

和LRU一样我们对这些信息进行抽样来选取待驱逐的数据。

然而和LRU不一样的是LFU有一些可调参数：比如，当一项经常被访问的数据不再被访问时应该以多快的速度降低它的排名？对特定的用例也可以通过调节`Morris counters range`来获取更佳的算法匹配。

在Redis4.0中默认的配置如下：

* 在大约一百万个请求时计数器饱和
* 每一分钟计数器衰减

这是饱经检验的合理值，但是我们可能需要调节配置信息来获取更理想的值

在`redis.conf`文件的例子中我们能看到如何调节这些参数的说明。但是简洁的说明一下它们是：

```
lfu-log-factor 10
lfu-decay-time 1
```

`decay time`(衰减时间)是计数器被衰减的分钟数，在采样时发现计数器早于该值应衰减。如果值是0则表示每次被扫描到的计数器都要进行衰减，0很少用到。

计数器的`logarithm factor`决定多少次命中将使得频率计数器饱和，它的范围是0-255。指数越高，所以需要更多的访问次数来达到最大值。指数越低对少量访问的计数器的分辨明显。具体参见下表：

```
+--------+------------+------------+------------+------------+------------+
| factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |
+--------+------------+------------+------------+------------+------------+
| 0      | 104        | 255        | 255        | 255        | 255        |
+--------+------------+------------+------------+------------+------------+
| 1      | 18         | 49         | 255        | 255        | 255        |
+--------+------------+------------+------------+------------+------------+
| 10     | 10         | 18         | 142        | 255        | 255        |
+--------+------------+------------+------------+------------+------------+
| 100    | 8          | 11         | 49         | 143        | 255        |
+--------+------------+------------+------------+------------+------------+
```

因此，基本上，指数是在具有较低访问频率时更好区分数据与在具有较高访问频率是的区分数据之间进行权衡。`redis.conf`文件的例子的评论中有更多的信息。